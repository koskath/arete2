# Slide 10 of Lecture 10 contains information about the Recurrent Neural Networks (RNNs).

• Computations within a recurrent layer:
• Each neuron in a recurrent layer (RL) receives as input, output of previous layer and its
current input.
• Neurons each have two weight vectors.
• Neurons perform an affine transformation of inputs and pass it through a non-linear
activation function (tanh).
• Within RL, output of neurons is moved to a dense or fully connected layer with a
softmax activation function as output of class probabilities.
10
