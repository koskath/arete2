# Slide 5 of Lecture 10 contains information about the BatchNorm.

• Note: If you add a BN layer as the very first layer of your NN, you do not need to
standardize your training set; the BN layer will do it for you.
• Vanishing gradients problem can be reduced to a point that activation functions can be
used for further solution.
• BN can improve many deep neural networks.
Bisong E. (2019) More on Optimization Techniques. In: Building Machine Learning and Deep Learning Models on Google Cloud Platform. Apress, Berkeley, CA
