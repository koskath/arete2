# Slide 25 of Lecture 13 contains information about the Adversarial Examples.

• ML models consistently misclassify adversarial examples from dataset
• such that perturbed input results in model outputting an incorrect answer with high
confidence.
• ML models misclassify examples that are only slightly different from correctly classified
examples drawn from data distribution.
• Adversarial examples are inputs formed by applying small but intentionally worst-case
perturbations.
Goodfellow et al. Explaining and Harnessing Adversarial Examples
