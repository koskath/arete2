# Slide 26 of Lecture 15 contains information about the What is AI alignment?.

• Process of encoding human values and goals into LLMs to make them helpful, safe,
and reliable.
• Goal: Enterprises can tailor AI models to follow their business rules and policies.
• Alignment happens during fine-tuning, when a foundation model is fed examples of
the target task.
• Involves two steps:
1. Instruction-tuning phase: LLMs are given examples of target task so it can learn
by example.
2. Critique phase: Human or another AI interacts with the model and grades its
responses in real-time.
• E.g., In RL, this step is called RL with human feedback (RLHF) or AI feedback
(RLAIF).
https://research.ibm.com/blog/what-is-alignment-ai
